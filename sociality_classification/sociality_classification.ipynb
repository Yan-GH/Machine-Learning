{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Requirements\n",
    "- Python (>=3.6)\n",
    "- PyTorch (>=1.2.0) \n",
    "- Jupyter (latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the necessary imports\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torchtext\n",
    "from torchtext.data import Field, LabelField\n",
    "from torchtext.data import TabularDataset\n",
    "from torchtext.data import Iterator, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed\n",
    "manual_seed = 572\n",
    "torch.manual_seed(manual_seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataset: [CL-Aff shared task](https://sites.google.com/view/affcon2019/cl-aff-shared-task?authuser=0). HappyDB is a dataset of about 100,000 `happy moments` crowd-sourced via Amazonâ€™s Mechanical Turk where each worker was asked to describe in a complete sentence `what made them happy in the past 24 hours`. Each user was asked to describe three such moments. \n",
    "\n",
    "The Task: sociality classification. (Here we only use labelled dataset which include 10,562 labelled samples)\n",
    "\n",
    "The dataset has already been preprocessed (tokenization, removing URLs, mentions, hashtags and so on) and placed it under ``data/happy_db`` folder in three files as ``train.tsv``, ``dev.tsv`` and ``test.tsv``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitespace_tokenize(text):\n",
    "    return text.strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define TorchText's Fields for tweet text and label respectively to handle how data should be processed\n",
    "TEXT = Field(sequential=True, tokenize=whitespace_tokenize, lower=True)\n",
    "LABEL = Field(sequential=False, unk_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process tsv files using TabularDataset class and Fields\n",
    "train, val, test = TabularDataset.splits(\n",
    "               path=\"data/happy_db/\", # the root directory where the data lies\n",
    "               train='train.tsv', validation=\"dev.tsv\", test=\"test.tsv\",\n",
    "               format='tsv',\n",
    "               skip_header=True,\n",
    "               fields=[('tweet', TEXT), ('label', LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build vocabulary to map words and labels to integers\n",
    "TEXT.build_vocab(train, max_size=5000)  # The maximum size of vocabulary is 5000\n",
    "LABEL.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of TEXT vocabularies: 5002\n",
      "The size of LABEL vocabularies: 2\n"
     ]
    }
   ],
   "source": [
    "### Check the sizes of two vocabularies individually\n",
    "TEXT_VOCAB_SIZE = len(TEXT.vocab.stoi)\n",
    "LABEL_VOCAB_SIZE = len(LABEL.vocab.stoi)\n",
    "print(\"The size of TEXT vocabularies:\", TEXT_VOCAB_SIZE)  # the extra 2 vocabularies are padding and unknown\n",
    "print(\"The size of LABEL vocabularies:\", LABEL_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Construct the Iterators to get the train, dev, and test splits\n",
    "train_iter, val_iter, test_iter = BucketIterator.splits(\n",
    "    (train, val, test), # we pass in the datasets we want the iterator to draw data from\n",
    "    batch_sizes=(32,32,32), #batch size for Train, dev and Test, respectively.\n",
    "    sort_key=lambda x: len(x.tweet),  # Samples are sorted by length.\n",
    "    sort=True, # sorting examples in order to batch together examples with similar lengths and minimize padding. \n",
    "    sort_within_batch=True  # sorts the data within each minibatch in decreasing order according to the sort_key.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMmodel(nn.Module):\n",
    "    '''LSTM classifier of the task'''\n",
    "    def __init__(self, embedding_size, vocab_size, output_size, hidden_size, num_layers, dropout):\n",
    "        super(LSTMmodel, self).__init__()\n",
    "        \n",
    "        # word embedding lookup table\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size)\n",
    "        self.embedding.weight.data.normal_(0, 0.05)  # The parameters of this embedding layer are randomly initialized from a normal distribution (mean 0 and variance 0.05)\n",
    "        \n",
    "        # core LSTM RNN module (uni-directional)\n",
    "        self.lstm_rnn = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers) \n",
    "        \n",
    "        # activation function\n",
    "        self.activation_fn = nn.Tanh()\n",
    "        \n",
    "        # classification related modules\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linear_layer = nn.Linear(in_features=hidden_size, out_features=output_size, bias=True) \n",
    "        self.softmax_layer = nn.LogSoftmax(dim=-1)  # normalize along batches\n",
    "        self.debug = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''define the forward propagation logic with debug mode'''\n",
    "        if self.debug:\n",
    "            print(\"input word indices shape = \", x.size())\n",
    "        out = self.embedding(x)\n",
    "        if self.debug:\n",
    "            print(\"word embeddings shape = \", out.size())\n",
    "        out, _ = self.lstm_rnn(out)\n",
    "        # LSTM output size: (seq_len, batch, num_directions * hidden_size)\n",
    "        if self.debug:\n",
    "            print(\"LSTM RNN output (features from last layer of RNN for all timesteps) shape = \", out.size())\n",
    "        out = out[-1]  # the last hidden of last layer in shape (batch, num_directions * hidden_size)\n",
    "        if self.debug:\n",
    "            print(\"Tweet embeddings or RNN output (features from last layer of RNN for the last timestep only) shape = \", out.size())\n",
    "        out = self.activation_fn(out)\n",
    "        out = self.dropout(out)\n",
    "        if self.debug:\n",
    "            print(\"Activation function output shape = \", out.size())\n",
    "        out = self.linear_layer(out)\n",
    "        if self.debug:\n",
    "            print(\"linear layer output shape = \", out.size())\n",
    "        out = self.softmax_layer(out)\n",
    "        if self.debug:\n",
    "            print(\"softmax layer output shape = \", out.size())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMmodel(\n",
      "  (embedding): Embedding(5002, 300)\n",
      "  (lstm_rnn): LSTM(300, 500, num_layers=2)\n",
      "  (activation_fn): Tanh()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (linear_layer): Linear(in_features=500, out_features=2, bias=True)\n",
      "  (softmax_layer): LogSoftmax(dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(manual_seed)\n",
    "torch.cuda.manual_seed(manual_seed)\n",
    "\n",
    "# hyperparameters\n",
    "WORD_VEC_SIZE = 300  # represent each token in a 300-dimentional vector\n",
    "HIDDEN_SIZE = 500  \n",
    "MAX_EPOCHS = 10 # number of passes over the training data\n",
    "NUM_LAYERS = 2\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT = 0.1\n",
    "\n",
    "# Instantiate the model with two uni-directional LSTM layers, each layer having 500 hidden units\n",
    "model = LSTMmodel(embedding_size=WORD_VEC_SIZE, vocab_size=TEXT_VOCAB_SIZE, output_size=LABEL_VOCAB_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=DROPOUT)\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create an SGD optimizer for training\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training and Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train(loader, model, criterion, optimizer, device):\n",
    "    total_loss = 0.0\n",
    "    # iterate throught the data loader\n",
    "    num_sample = 0\n",
    "    for batch in loader:\n",
    "        # load the current batch\n",
    "        batch_input = batch.tweet\n",
    "        batch_output = batch.label\n",
    "        \n",
    "        batch_input = batch_input.to(device)\n",
    "        batch_output = batch_output.to(device)\n",
    "        # forward propagation\n",
    "        model_outputs = model(batch_input)\n",
    "        # compute the loss\n",
    "        cur_loss = criterion(model_outputs, batch_output)\n",
    "        total_loss += cur_loss.item()\n",
    "\n",
    "        # backward propagation\n",
    "        # clear the buffer\n",
    "        optimizer.zero_grad()\n",
    "        # compute the gradients\n",
    "        cur_loss.backward()\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        num_sample += batch_output.shape[0]\n",
    "    return total_loss/num_sample\n",
    "\n",
    "# evaluation logic based on classification accuracy\n",
    "def evaluate(loader, model, criterion, device):\n",
    "    all_pred=[]\n",
    "    all_label = []\n",
    "    with torch.no_grad(): # impacts the autograd engine and deactivate it. reduces memory usage and speeds up computation\n",
    "        for batch in loader:\n",
    "             # load the current batch\n",
    "            batch_input = batch.tweet\n",
    "            batch_output = batch.label\n",
    "\n",
    "            batch_input = batch_input.to(device)\n",
    "            # forward propagation\n",
    "            model_outputs = model(batch_input)\n",
    "            # identify the predicted class for each example in the batch\n",
    "            probabilities, predicted = torch.max(model_outputs.cpu().data, 1)\n",
    "            # put all the true labels and predictions to two lists\n",
    "            all_pred.extend(predicted)\n",
    "            all_label.extend(batch_output)\n",
    "            \n",
    "    accuracy = accuracy_score(all_label, all_pred)\n",
    "    f1score = f1_score(all_label, all_pred, average='macro') \n",
    "    return accuracy,f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0114, Training Accuracy: 0.9259, Training F1: 0.9258, Validation Accuracy: 0.8873, Validation F1: 0.8869\n",
      "Epoch [2/10], Loss: 0.0072, Training Accuracy: 0.9457, Training F1: 0.9456, Validation Accuracy: 0.8949, Validation F1: 0.8943\n",
      "Epoch [3/10], Loss: 0.0051, Training Accuracy: 0.9618, Training F1: 0.9617, Validation Accuracy: 0.8873, Validation F1: 0.8869\n",
      "Epoch [4/10], Loss: 0.0039, Training Accuracy: 0.9657, Training F1: 0.9656, Validation Accuracy: 0.8930, Validation F1: 0.8922\n",
      "Epoch [5/10], Loss: 0.0035, Training Accuracy: 0.9667, Training F1: 0.9667, Validation Accuracy: 0.8788, Validation F1: 0.8785\n",
      "Epoch [6/10], Loss: 0.0028, Training Accuracy: 0.9740, Training F1: 0.9739, Validation Accuracy: 0.8797, Validation F1: 0.8795\n",
      "Epoch [7/10], Loss: 0.0023, Training Accuracy: 0.9587, Training F1: 0.9587, Validation Accuracy: 0.8627, Validation F1: 0.8626\n",
      "Epoch [8/10], Loss: 0.0021, Training Accuracy: 0.9827, Training F1: 0.9827, Validation Accuracy: 0.8797, Validation F1: 0.8793\n",
      "Epoch [9/10], Loss: 0.0017, Training Accuracy: 0.9818, Training F1: 0.9817, Validation Accuracy: 0.8741, Validation F1: 0.8739\n",
      "Epoch [10/10], Loss: 0.0012, Training Accuracy: 0.9914, Training F1: 0.9913, Validation Accuracy: 0.8788, Validation F1: 0.8782\n",
      "Best validation score for iterations #2: 0.8943245039023375\n"
     ]
    }
   ],
   "source": [
    "### start the training\n",
    "best_f1 = 0\n",
    "best_epoch = 0\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    # train the model for one pass over the data\n",
    "    train_loss = train(train_iter,model,criterion,optimizer,device)  \n",
    "    # compute the training accuracy\n",
    "    train_acc, train_f1 = evaluate(train_iter,model,criterion,device)\n",
    "    # compute the validation accuracy\n",
    "    val_acc, val_f1 = evaluate(val_iter,model,criterion,device)\n",
    "    \n",
    "    if val_f1 > best_f1:\n",
    "        best_f1 = val_f1\n",
    "        best_epoch = epoch+1\n",
    "\n",
    "        # save model, optimizer, and number of epoch to a dictionary\n",
    "        model_save = {\n",
    "            'epoch': epoch,  # number of epoch\n",
    "            'model_state_dict': model.state_dict(),  # model parameters \n",
    "            'optimizer_state_dict': optimizer.state_dict(),  # save optimizer \n",
    "            'loss': train_loss  # training loss\n",
    "        }\n",
    "\n",
    "        # save model \n",
    "        torch.save(model_save, \"./ckpt/best_model.pt\")\n",
    "    # print the loss for every epoch\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}, Training Accuracy: {:.4f}, Training F1: {:.4f}, Validation Accuracy: {:.4f}, Validation F1: {:.4f}'.format(epoch+1, MAX_EPOCHS, train_loss, train_acc, train_f1, val_acc, val_f1))\n",
    "print(\"Best validation score for iterations #{}: {}\".format(best_epoch,best_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMmodel(\n",
       "  (embedding): Embedding(5002, 300)\n",
       "  (lstm_rnn): LSTM(300, 500, num_layers=2)\n",
       "  (activation_fn): Tanh()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (linear_layer): Linear(in_features=500, out_features=2, bias=True)\n",
       "  (softmax_layer): LogSoftmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Evaluate the best trained model on test set\n",
    "model2 = LSTMmodel(embedding_size=WORD_VEC_SIZE, vocab_size=TEXT_VOCAB_SIZE, output_size=LABEL_VOCAB_SIZE, hidden_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, dropout=DROPOUT)\n",
    "model2.to(device)\n",
    "# load checkpoint \n",
    "checkpoint = torch.load(\"./ckpt/best_model.pt\")\n",
    "\n",
    "# assign the parameters of checkpoint to this new model\n",
    "model2.load_state_dict(checkpoint['model_state_dict'])\n",
    "model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 88.352%, Test F1-score: 88.269%\n"
     ]
    }
   ],
   "source": [
    "# evaluate \n",
    "test_acc, test_f1 = evaluate(test_iter,model2,criterion,device)\n",
    "print('Test Accuracy: {:.3f}%, Test F1-score: {:.3f}%'.format(test_acc*100, test_f1*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
